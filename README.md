# LLM-PROJECT-A5-Analysis-of-Linguistic-Stereotypes-in-Generative-AI
 ## Instruction to run experiments related to : Trait adjective assignment based on statement

This experiment uses poetry to install all dependecies
here are the instruction to download it .
https://python-poetry.org/docs/#installing-with-pipx

Then, on the terminal on this folder , write :
'poetry install' 
to install all dependencies.





To generate llm responses you need to access an api for the model used ( gpt-4-mini in this case) , to do so insert your vercel api key in file adjective_experiments.py .

Here are instruction on how to create that api key:
https://vercel.com/docs/ai-gateway/authentication-and-byok/authentication

You can delete the previously generated logs in analysis_adjective_by_adri/results_role_prompting.jsonl and  test_multiple_napoli/2from_dataset_answers_napoletano_templated.jsonl
then run the file adjective_experiments.py to generate again the log of all responses (it will take several hours to run ).

To generate graphs and tables of the analysis go to to_show_role_prompting.ipynb and run the notebook, graphs used in the paper are in that notebook.
Use as kernel for the notebook the one generated by poetry. 

## Instruction to run experiments related to : Criminality analysis based on character descriptions

Run function run_gpt_criminality() in main.py. An API key for GPT-4.1 mini is required, it must be inserted in call_apis/call_api_gpt_by_gio.py 

Dependencies:
- openai
- pyyaml

To compute the results, run function analyze_results(input_json) in main.py .

## Instruction to run experiments related to : Hierarchical positioning analysis
The code related to this experiment is contained in test_hierarchy/analysis.py

Dependencies
- pandas (Data manipulation)
- numpy (Mathematical operations)
- matplotlib (Radar charts)
- openai (LLM API interaction)
- pyyaml (Configuration/API Key loading)

mukti agent pipeline: execute run_manager_assistant_test()

## Instruction to run experiments related to : Character analysis
all the code written for this section is contained in test_character/analysis.py

Dependencies
- pandas (Data manipulation)
- numpy (Mathematical operations)
- matplotlib (Radar charts)
- openai (LLM API interaction)
- pyyaml (Configuration/API Key loading)

baseline: execute function run_analysis(), it will automatically extract the phrases from the all_dialect_traslated.csv file

multi agent: execute function run_3agents() to execute the 3 agents analysis

to get plots: run plot_radar_chart() with the right parameters.
